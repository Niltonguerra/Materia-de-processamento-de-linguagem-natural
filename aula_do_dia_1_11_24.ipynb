{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdUWgfZ1qEs0NQ48fnrnbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niltonguerra/Materia-de-processamento-de-linguagem-natural/blob/main/aula_do_dia_1_11_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SpJ8OLj1PRcq"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original = 'olá!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e Letras maiúsculas.'\n",
        "\n",
        "texto_limpo = re.sub(r'[^A-Za-zÀ-ÿ\\s]','',original)\n",
        "\n",
        "texto_normalizado = texto_limpo.lower()\n",
        "\n",
        "\n",
        "print(f'Texto original: {original}')\n",
        "print(f'\\nTexto limpo: {texto_limpo}')\n",
        "print(f'\\nTexto normalizado: {texto_normalizado}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypBdJCmIP3F3",
        "outputId": "ba8be490-8f2c-438d-b2a5-ed1bd1f3327e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: olá!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e Letras maiúsculas.\n",
            "\n",
            "Texto limpo: olá Este é um exemplo de texto com várias PONTUAÇÕES símbolos especiais e Letras maiúsculas\n",
            "\n",
            "Texto normalizado: olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Baixa o recurso de tokenização, se necessário\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# Função para tokenizar texto com tratamento de erro\n",
        "def tokenize_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        raise ValueError(\"O texto de entrada deve ser uma string.\")\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Exemplo de uso\n",
        "texto_normalizado = \"Aqui está o texto para ser tokenizado.\"\n",
        "tokens = tokenize_text(texto_normalizado)\n",
        "\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFrEtTFXRIvE",
        "outputId": "4ff1ed4a-de1d-402a-eafe-c5075cc60f84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aqui', 'está', 'o', 'texto', 'para', 'ser', 'tokenizado', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "token_sem_stopwords = [palavra for palavra in tokens if palavra.lower() not in stopwords_pt]\n",
        "print(token_sem_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c3jVcQOS_N-",
        "outputId": "915e34c7-750b-4be7-b054-882ece662e88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aqui', 'texto', 'tokenizado', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mimetização ou lemetização\n",
        "\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "nltk.download('rslp')\n",
        "\n",
        "stemmer = RSLPStemmer()\n",
        "stemming = [stemmer.stem(palavra) for palavra in token_sem_stopwords]\n",
        "print(stemming)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqj_yZc3YTY8",
        "outputId": "c9078bd9-8673-4b6c-e157-63f9684511f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aqu', 'text', 'token', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDx9lYg_Y0QA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}