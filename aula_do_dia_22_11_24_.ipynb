{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIYuDgbN7CX4TcPoFkq+N4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niltonguerra/Materia-de-processamento-de-linguagem-natural/blob/main/aula_do_dia_22_11_24_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ryi1sNxi0_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpJ8OLj1PRcq"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original = 'olá!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e Letras maiúsculas.'\n",
        "\n",
        "texto_limpo = re.sub(r'[^A-Za-zÀ-ÿ\\s]','',original)\n",
        "\n",
        "texto_normalizado = texto_limpo.lower()\n",
        "\n",
        "\n",
        "print(f'Texto original: {original}')\n",
        "print(f'\\nTexto limpo: {texto_limpo}')\n",
        "print(f'\\nTexto normalizado: {texto_normalizado}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypBdJCmIP3F3",
        "outputId": "ba8be490-8f2c-438d-b2a5-ed1bd1f3327e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: olá!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e Letras maiúsculas.\n",
            "\n",
            "Texto limpo: olá Este é um exemplo de texto com várias PONTUAÇÕES símbolos especiais e Letras maiúsculas\n",
            "\n",
            "Texto normalizado: olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Baixa o recurso de tokenização, se necessário\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# Função para tokenizar texto com tratamento de erro\n",
        "def tokenize_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        raise ValueError(\"O texto de entrada deve ser uma string.\")\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Exemplo de uso\n",
        "texto_normalizado = \"Aqui está o texto para ser tokenizado.\"\n",
        "tokens = tokenize_text(texto_normalizado)\n",
        "\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFrEtTFXRIvE",
        "outputId": "4ff1ed4a-de1d-402a-eafe-c5075cc60f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aqui', 'está', 'o', 'texto', 'para', 'ser', 'tokenizado', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "token_sem_stopwords = [palavra for palavra in tokens if palavra.lower() not in stopwords_pt]\n",
        "print(token_sem_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c3jVcQOS_N-",
        "outputId": "915e34c7-750b-4be7-b054-882ece662e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aqui', 'texto', 'tokenizado', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mimetização ou lemetização\n",
        "\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "nltk.download('rslp')\n",
        "\n",
        "stemmer = RSLPStemmer()\n",
        "stemming = [stemmer.stem(palavra) for palavra in token_sem_stopwords]\n",
        "print(stemming)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqj_yZc3YTY8",
        "outputId": "c9078bd9-8673-4b6c-e157-63f9684511f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aqu', 'text', 'token', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1 - Criar o corpus\n",
        "# O corpus é uma lista de tuplas, onde cada tupla contém uma frase e um rótulo de classe ('positivo' ou 'negativo').\n",
        "corpus = [\n",
        "    (\"Eu amo PLN\", \"positivo\"),         # Exemplo de frase positiva\n",
        "    (\"Eu odeio bugs\", \"negativos\"),     # Exemplo de frase negativa (observe o erro no rótulo \"negativos\" -> \"negativo\")\n",
        "    (\"Amo resolver problemas\", \"positivo\"), # Exemplo de frase positiva\n",
        "    (\"Odeio erros\", \"negativo\"),         # Exemplo de frase negativa\n",
        "    (\"Bugs legais\",\"positivo\"),\n",
        "    (\"Resolver\",\"positivo\"),\n",
        "    (\"Eu não\",\"negativo\")\n",
        "    ]\n",
        "\n",
        "# Passo 2 - Processar o texto\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Função para pré-processar o texto\n",
        "# Converte o texto para minúsculas e divide em palavras (tokens)\n",
        "def preprocess_text(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())  # Retorna uma lista de palavras encontradas no texto\n",
        "\n",
        "# Processa o corpus aplicando o pré-processamento em cada frase\n",
        "# Retorna uma lista de tuplas: (lista de palavras, rótulo)\n",
        "processed_corpus = [(preprocess_text(text), label) for text, label in corpus]\n",
        "print(processed_corpus)\n",
        "\n",
        "# Passo 3 - Calculando probabilidades\n",
        "# Inicializa contadores para as classes, palavras e total de palavras por classe\n",
        "class_counts = Counter()            # Conta a quantidade de exemplos por classe\n",
        "word_counts = defaultdict(Counter)  # Conta a ocorrência de palavras em cada classe\n",
        "total_words = defaultdict(int)      # Total de palavras em cada classe\n",
        "\n",
        "# Itera pelo corpus processado para calcular as contagens necessárias\n",
        "for words, label in processed_corpus:\n",
        "    class_counts[label] += 1  # Incrementa o contador da classe\n",
        "    for word in words:\n",
        "        word_counts[label][word] += 1  # Incrementa o contador da palavra para a classe correspondente\n",
        "        total_words[label] += 1        # Incrementa o total de palavras na classe\n",
        "\n",
        "# Calcula a probabilidade a priori de cada classe: P(classe)\n",
        "# Isso é feito dividindo o número de exemplos em cada classe pelo total de exemplos\n",
        "total_examples = sum(class_counts.values())\n",
        "prior_probabilities = {cls: count / total_examples for cls, count in class_counts.items()}\n",
        "\n",
        "# Função para calcular a probabilidade condicional de uma palavra dada uma classe: P(palavra|classe)\n",
        "# Usa suavização de Laplace (alpha) para evitar problemas com palavras desconhecidas\n",
        "def conditional_probability(word, label, alpha=1):\n",
        "    return (word_counts[label][word] + alpha) / (total_words[label] + alpha * len(word_counts[label]))\n",
        "\n",
        "# Passo 4 - Classificar um novo texto\n",
        "# Função para prever a classe de um texto\n",
        "def predict(text):\n",
        "    words = preprocess_text(text)  # Pré-processa o texto de entrada\n",
        "    probabilities = {}             # Armazena as probabilidades para cada classe\n",
        "\n",
        "    # Calcula a probabilidade para cada classe\n",
        "    for label in class_counts.keys():\n",
        "        probabilities[label] = prior_probabilities[label]  # Começa com a probabilidade a priori: P(classe)\n",
        "        for word in words:\n",
        "            probabilities[label] *= conditional_probability(word, label)  # Multiplica pela probabilidade condicional: P(palavra|classe)\n",
        "\n",
        "    # Retorna a classe com maior probabilidade e as probabilidades calculadas\n",
        "    return max(probabilities, key=probabilities.get), probabilities\n",
        "\n",
        "# Passo 5 - Teste com um novo texto\n",
        "novo_texto = \"eu amo resolver bugs\"  # Texto a ser classificado\n",
        "classe, probs = predict(novo_texto) # Chama a função de predição\n",
        "\n",
        "# Imprime o resultado\n",
        "print(f'Texto: \"{novo_texto}\"')           # Mostra o texto de entrada\n",
        "print(f'Classe prevista: `{classe}`')     # Mostra a classe prevista\n",
        "print(f'Probabilidades:')                 # Mostra as probabilidades calculadas\n",
        "for label, prob in probs.items():\n",
        "    print(f\"{label}: {prob}\")             # Mostra a probabilidade de cada classe\n"
      ],
      "metadata": {
        "id": "iDx9lYg_Y0QA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29267acd-9598-44e3-bd38-1758d513036e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['eu', 'amo', 'pln'], 'positivo'), (['eu', 'odeio', 'bugs'], 'negativos'), (['amo', 'resolver', 'problemas'], 'positivo'), (['odeio', 'erros'], 'negativo'), (['bugs', 'legais'], 'positivo'), (['resolver'], 'positivo'), (['eu', 'não'], 'negativo')]\n",
            "Texto: \"eu amo resolver bugs\"\n",
            "Classe prevista: `negativos`\n",
            "Probabilidades:\n",
            "positivo: 0.00031389508928571425\n",
            "negativos: 0.0004409171075837742\n",
            "negativo: 0.00013950892857142856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1 importação das bibliotecas a serem utilizadas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Passo 2 dados exemplo\n",
        "corpus = [\n",
        "    \"Eu amo PLN\", \"Eu odeio bugs\", \"Eu amo resolver problemas\",\n",
        "    \"Odeio erros\",\"Amo programação\",\"Não gosto de falhas\"\n",
        "]\n",
        "\n",
        "classes = [\"negativo\",\"negativo\",\"positivo\",\"negativo\",\"positivo\",\"negativo\"]\n",
        "\n",
        "# Passo 3 Pre processamento e vetorização\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "y = classes\n",
        "\n",
        "#Passo 4 Dividir os dados e treinar o modelo\n",
        "X_train,X_test,y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=42)\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#Passo 5 Avaliar o modelo\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ToHlDtPTQt8",
        "outputId": "1cfcd935-bc38-4caa-bd1e-5e8a8f40b13f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      0.50      0.67         2\n",
            "    positivo       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.50      0.25      0.33         2\n",
            "weighted avg       1.00      0.50      0.67         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "análise desse relatório:\n",
        "\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "     negativo       1.00      0.50      0.67         2\n",
        "     positivo       0.00      0.00      0.00         0\n",
        "\n",
        "     accuracy                           0.50         2\n",
        "     macro avg       0.50      0.25      0.33         2\n",
        "     weighted avg       1.00      0.50      0.67         2\n",
        "\n",
        "#####Métricas por Classe:\n",
        "Cada classe (aqui negativo e positivo) tem métricas calculadas individualmente.\n",
        "\n",
        "#####Métricas Agregadas:\n",
        "\n",
        "Métricas como accuracy, macro avg, e weighted avg mostram uma visão geral do modelo.\n",
        "Termos Importantes\n",
        "#####Precision (Precisão):\n",
        "A proporção de previsões corretas para uma classe específica, ou seja, True Positives / (True Positives + False Positives).\n",
        "Mede o quão preciso o modelo é ao prever essa classe.\n",
        "#####Recall (Sensibilidade):\n",
        "A proporção de exemplos verdadeiros de uma classe que o modelo conseguiu identificar, ou seja, True Positives / (True Positives + False Negatives).\n",
        "Mede o quão bem o modelo encontra todos os exemplos de uma classe.\n",
        "F1-Score:\n",
        "A média harmônica entre precisão e recall. É útil quando há um desequilíbrio entre as classes.\n",
        "Fórmula: 2 * (precision * recall) / (precision + recall).\n",
        "#####Support (Suporte):\n",
        "O número total de exemplos reais de cada classe no conjunto de teste.\n",
        "####Análise do Relatório:\n",
        "#####Classe: negativo\n",
        "Precisão (Precision): 1.00\n",
        "Todas as previsões feitas para a classe negativo estavam corretas (nenhum falso positivo).\n",
        "#####Recall (Sensibilidade): 0.50\n",
        "Apenas 50% dos exemplos reais da classe negativo foram corretamente identificados.\n",
        "F1-Score: 0.67\n",
        "Combinação de precisão e recall; mostra um desempenho moderado nesta classe.\n",
        "Support: 2\n",
        "Existiam 2 exemplos da classe negativo no conjunto de teste.\n",
        "#####Classe: positivo\n",
        "Precisão (Precision): 0.00\n",
        "Nenhuma previsão correta foi feita para a classe positivo.\n",
        "#####Recall (Sensibilidade): 0.00\n",
        "O modelo não identificou nenhum exemplo da classe positivo.\n",
        "F1-Score: 0.00\n",
        "O desempenho nesta classe foi nulo.\n"
      ],
      "metadata": {
        "id": "e6Rw7qtQgYQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importar Bibliotecas\n",
        "# Importa bibliotecas essenciais para pré-processamento, modelagem e avaliação.\n",
        "import nltk  # Para manipular dados textuais e datasets embutidos\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Para transformar textos em vetores TF-IDF\n",
        "from sklearn.model_selection import train_test_split  # Para dividir o conjunto de dados em treino e teste\n",
        "from sklearn.naive_bayes import MultinomialNB  # Modelo Naive Bayes para classificação\n",
        "from sklearn.svm import SVC  # Máquina de Vetores de Suporte (SVM) para classificação\n",
        "from sklearn.metrics import classification_report  # Para avaliar o desempenho do modelo\n",
        "from sklearn.preprocessing import LabelEncoder  # Para transformar rótulos categóricos em numéricos\n",
        "\n",
        "# Baixar o dataset de exemplo\n",
        "nltk.download('movie_reviews')  # Faz o download do dataset \"movie_reviews\" do NLTK\n",
        "from nltk.corpus import movie_reviews  # Importa o corpus de análises de filmes\n",
        "\n",
        "# 2. Preparação dos dados\n",
        "\n",
        "# Coleta de textos e classes\n",
        "# O dataset contém textos (palavras de reviews de filmes) e suas categorias ('pos' ou 'neg').\n",
        "# Aqui, combinamos as palavras de cada documento em uma string e associamos com sua categoria.\n",
        "documents = [\n",
        "    (\" \".join(movie_reviews.words(fileid)), category)  # Junta as palavras de cada documento em uma única string\n",
        "    for category in movie_reviews.categories()  # Itera pelas categorias ('pos' e 'neg')\n",
        "    for fileid in movie_reviews.fileids(category)  # Itera pelos arquivos de cada categoria\n",
        "]\n",
        "\n",
        "# Separar textos e rótulos\n",
        "# Separa o texto das análises (texts) e suas respectivas categorias (labels).\n",
        "texts, labels = zip(*documents)\n",
        "\n",
        "# Transformar rótulos (positivo/negativo) em 0 e 1\n",
        "# Usa o LabelEncoder para converter as categorias ('pos' e 'neg') em números (0 e 1).\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Dividir dados em treino e teste\n",
        "# Divide o dataset em 70% para treino e 30% para teste.\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
        "    texts, labels, test_size=0.3, random_state=42  # Define uma semente para garantir reprodutibilidade\n",
        ")\n",
        "\n",
        "# 3. Representação do texto com TF-IDF\n",
        "\n",
        "# Criar o vetorizador TF-IDF\n",
        "# O TF-IDF converte os textos em vetores numéricos, representando a relevância das palavras nos documentos.\n",
        "# Limitamos a 5000 palavras mais frequentes para reduzir a dimensionalidade.\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Ajustar e transformar os textos de treino\n",
        "# O método fit_transform ajusta o vetor TF-IDF aos dados de treino e os transforma em vetores numéricos.\n",
        "X_train = vectorizer.fit_transform(texts_train)\n",
        "\n",
        "# Transformar os textos de teste\n",
        "# Apenas transforma os textos de teste com base no modelo ajustado aos dados de treino.\n",
        "X_test = vectorizer.transform(texts_test)\n",
        "\n",
        "# 4. Treinar os modelos\n",
        "\n",
        "# Treinamento do Naive Bayes\n",
        "# Ajusta o modelo Naive Bayes Multinomial aos vetores de treino e seus rótulos.\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, labels_train)\n",
        "\n",
        "# Predição do Naive Bayes\n",
        "# Gera as previsões do modelo Naive Bayes para os textos de teste.\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "\n",
        "# Treinamento do SVM\n",
        "# Ajusta o modelo SVM com kernel linear aos vetores de treino e seus rótulos.\n",
        "svm_model = SVC(kernel=\"linear\", random_state=42)\n",
        "svm_model.fit(X_train, labels_train)\n",
        "\n",
        "# Predição do SVM\n",
        "# Gera as previsões do modelo SVM para os textos de teste.\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "# 5. Avaliação\n",
        "\n",
        "# Avaliação do Naive Bayes\n",
        "# Exibe o relatório de classificação para o modelo Naive Bayes.\n",
        "# Inclui métricas como precisão (precision), sensibilidade (recall) e F1-Score para cada classe.\n",
        "print(\"Naive Bayes Performance:\")\n",
        "print(classification_report(labels_test, nb_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "# Avaliação do SVM\n",
        "# Exibe o relatório de classificação para o modelo SVM.\n",
        "print(\"SVM Performance:\")\n",
        "print(classification_report(labels_test, svm_predictions, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zqG6WbmWedy",
        "outputId": "eb4a2f9a-0103-40ea-cd1e-9050f7443d1c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.79      0.84      0.81       302\n",
            "         pos       0.82      0.77      0.80       298\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n",
            "SVM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.80      0.81       302\n",
            "         pos       0.81      0.82      0.81       298\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpyWSkv9gBje"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}